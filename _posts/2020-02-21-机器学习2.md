---
title: 机器学习 02 模型评估 01 前端
tags: 
  - 机器学习
---

我们知道，机器学习是给学习算法输入大量样本，使算法产生一个可以预测未知用例的泛化模型的过程。那么我们首先就需要知道，对于一个算法，我们如何评估它对一个未知输入进行预测的能力呢？

首先我们需要知道我们想要的是什么，我们要将“它对一个未知输入进行预测的能力”进行一个准确的描述，它是：在预测任务中，对于样例集合$D=\{(x_1, y_1), (x_2, y_2), \cdots\}$中的每一个输入均有输出$f(x_i)$：那么我们定义性地描述**模型**对于样例集D的误差是：
$$ E(f; D) = \frac{1}{m} \sum^{m}_{i=1}(f(x_i) - y_i)^2$$
这个式子被称为均方误差。

那么我们就先考虑一下对于一个模型，我们如何收集它的数据来求它的均方误差：

## 评估方法

“如何收集数据”这个问题，对于机器学习模型来讲就是“如何设置测试用例”的问题。很直观的，这个用例应当能够反映真实情况下的分布，否则我们得到的结果不能代表泛化情况下的模型质量；其次，为了保证泛化性，我们的测试用例应尽量与训练用例互斥。下面有几个常用的采样方式：

### 留出法

留出法直接将数据集划分为两个互斥的集合，一个作为训练集、一个作为测试集。注意，这个划分过程应当保持划分前后数据分布的一致，即使用分层采样；以及单次随机划分得到的结果往往不可靠，一般我们需要多次划分。

留出法的明显不足在于：由于训练集和测试集互斥，如果测试集过大，就会导致训练用例不足，导致算法产生的模型与真实情况下的模型差距过大；如果训练集过大，就会导致测试用例不足，导致测试的质量偏低。这是一个平衡的艺术，一般选择总集的2/3~4/5来训练，其余的拿来测试。一般来讲，测试集应至少包含30个样例。

### k折交叉验证法

这个方法将数据总集分层地划为k等份，每次拿出一个作为测试用例，其余作为训练集。交叉验证法的质量很大程度取决于k的取值，k一般取值是10.  
一般这个过程要反复k次，直到所有集合都成为过一次测试集，称为k次k折交叉验证。  
特殊地，如果k的大小等于总集的大小，每个小区间只有1个样本，此时算法产生的模型可以非常好地保持在总集作为训练集时的性质，评估的结果被认为比较准确。这个算法特殊地被称为留一法。  
交叉验证法的最大问题就是：慢。

### 自助采样法

对于很少的总集，我们对于大小为m的总集，有放回地抽取m次元素作为训练集。显然，被抽取出的元素中一定存在重复。微积分计算得到，对于很大的样本，总集中有占比1/e的元素不会被抽取到。那么我们将抽取出的元素作为训练集，没有抽到的元素作为测试集，我们就有了m大小的经过随机抽样得到的分布良好的训练集，和占总量1/3左右的测试集。  
这种方法对于小规模的总集很有效，但是它少量改变了初始数据集的分布情况，引入训练偏差。
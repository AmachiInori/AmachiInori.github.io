---
title: 机器学习 02 模型评估 02 数据分析：样例和泛化之间(1)
tags: 
  - 机器学习
---

上一节我们讨论了基于测试集的非泛化情况下的模型表征，现在我们将目光逐渐转向泛化的情况：

### ROC曲线和正例阈值选择

重复我们之前使用过的方法：将输入样例按照模型给出的概率预测排序，最有可能是正例的排在前边，最不可能是正例的排在后边。比如，一串输入序列(这里只描述输入的真实属性)：

`+ + - + + - - + - - -`

我们将第i个元素之前的样例视为正例，然后根据这些样例的本质属性给他们分为"真正例"(本质是正例)和"假正例"(本质是反例)。比如，我们要视上述序列的第3个(从0开始)之前的所有样例为正例，此时第0、1个为真正例，第2个为假正例。我们分别将真正例数除以样例中的所有真正的正例数算出**真正例率**，将假正例数除以样例中的所有真正的反例数算出**假正例率**：

真正例率 $TPR = \frac{TP}{TP+FN}$  
假正例率 $FPR = \frac{FP}{TN+FP}$  

在坐标轴上描出$(FPR, TPR)$，依次变化i从`0-array.size()`，作出`array.size() + 1`个点，连起来，就形成了一条折线，这条线我们称为“ROC曲线”(受试者工作特征曲线)。它的统计方式与P-R曲线完全一致，但是由于算法上的差异，它能够更好地屏蔽测试集的影响，能够较好地反映模型的泛化特征。  

![ROC曲线](/assets/image/ML/ROC.png)  

ROC曲线的积分(图像下的面积)被称为AUC，AUC越大表明基于预测概率的排序越准确，图像中的$FPR = TPR$线反映的是随机取值模型的特征，因此AUC应至少大于0.5。完全正确的测试模型的ROC图像覆盖整个$x, y\in[0,1]$。

对于有限用例产生的$m$对$(FPR, TPR)$，AUC的面积直观地估算为：  

$$\sum^{m-1}_{i=1}(x_{i+1}-x_i)\frac{(y_i+y_{i+1})}{2}$$

#### ROC与P-R

还记得我们在P-R图时举的例子吗：

```
有一个集合全部是正例，另一个集合只有一个正例，二者的P-R图就会出现很大的差距。故P-R图一般用来描述模型在一个特定测试集上的性能，它基本上是不泛化的。
```

对于这个例子，ROC曲线由于算法的不同，会大概率得出两个完全一致的图像。这是由于P和R高度相关，样本的扰动会对其造成很大的影响，而FPR和TPR的相关度很弱，所以在一定程度上减弱了样本所带来的影响。
---
title: 机器学习 02 模型评估 02 数据分析：在测试集上(1)
tags: 
  - 机器学习
---

上一节我们描述了收集模型对应数据的方法，这一节我们就来处理收集的数据。

请注意，以下述方法进行的性能分析基于的基础是我们的测试数据集，得出的结果在任何意义上都不可以代表泛化情况下的性能数据。

## 性能度量

### 准确性

关于机器学习模型准确性的度量一般有如下几个：

第一个是我们在上一节中提到的

#### 均方误差

对于样例集合$D=\{(x_1, y_1), (x_2, y_2), \cdots\}$中的每一个输入均有输出$f(x_i)$：那么我们定义性地描述**模型**对于样例集D的误差是：  
$$ E(f; D) = \frac{1}{m} \sum^{m}_{i=1}(f(x_i) - y_i)^2$$  
这个式子被称为均方误差。

对于二分类问题(也就是输出是bool值的问题)，我们有一个特殊的准确性描述方式：

#### 错误率、精度

错误率就是输出错误的测试样例占全部样例的比例。对于样例集合D，准确率可以写为：

$$E(f;D)=\frac{1}{m} \sum^{m}_{i=1}I(f(x_i)\neq y_i)$$  

其中  

$$I(x) = x \ ? \ 1 \ : \ 0 $$

这个式子实际上就是将bool结果视为0和1，代入到均方误差表达式中再进行简单的化简之后的结果。

而精度则为：

$$acc(f:D) = 1 - E(f;D) = \frac{1}{m} \sum^{m}_{i=1}I(f(x_i)= y_i)$$

在样例连续分布情况下，可写为积分形式：

$$E(f;D)=\frac{1}{m} \int_{D}I(f(x_i)\neq y_i)P(x_i)$$

以错误率和精度为代表的准确性度量是描述模型输出的宏观状态所用的指标。

### 查准率和查全率

针对二分类问题：我们观察到二分类问题可能有两种错误：

1. 本该属于正例的被分为了反例
2. 本该属于反例的被分为了正例

我们以正例的视角去看：问题会转化为

1. 该被分入的没有被分入，即分类的全面性有误
2. 不该被分入的错误地被分入了，即分类的准确性有误

那么我们称1为查全率问题，2为查准率问题。相应地，查全率定义为**被挑选出的正例与全部的正例之比**；查全率定义为**挑选出的正例中真正的正例与被挑选出的观测正例之比**。考虑二分类问题的混淆表：

|  | 预测正例 | 预测反例 |
| :-----: | :-----: | :-----: |
| 真实正例 | TP | FN |
| 真实反例 | FP | TN |  

(描述分类结果的两个字母中，首个字母表示分类结果的正确性`True`和`False`；第二个字母表示分类结果`Positive`和`Nagetive`)

那么查全率定义为 $R = \frac{TP}{TP + FN}$(recall)， 查准率定义为 $P=\frac{TP}{TP+FP}$(precision)。

在描述全局性误差(错误率)之外，我们需要讨论上述两个指标来让*异化不同错误的代价*成为可能。

在进一步讨论之前，我们先来看一种二分类模型预测一系列样例的执行过程：

1. 首先分析样例输入的属性空间，对于每一个样例，基于模型和属性空间对它产生一个实数预测值。
2. 将每一个样例以上述预测值为主键排序
3. 基于给定的(或者是模型通过学习生成的)一个阈值来分类，预测值高于阈值的分为正例，低于预测值的分为反例

那么我们很容易想到，如果这个阈值变高，选出的样例就越有可能是正例，查准率很可能会上升；但同时选择的样例数会减少，查全率很可能下降。反之，如果这个阈值变低，选出的样例数会增大，查全率很可能上升，但查准率很可能会下降。所以我们认为，查全率和查准率存在一个**不严格的负相关关系**。

#### P-R图、BEP

这就产生了我们的一种直观分析查全率和查准率的手段：对于某一个模型对于某一组样例产生的一个预测值序列，我们人为地控制其正例阈值，测定不同阈值下的查全率R和查准率P，将点$(R, P)$绘制在坐标轴上并连起来，举例：

![PR曲线](/assets/image/ML/PR.png)  

这个曲线被称为P-R曲线。分析：P-R曲线直观地反映了目前的模型在目前的样例集上的查全率和查准率表现，有一条重要结论：查准率随查全率下降得越慢，表示预测值序列越接近真实值序列，即模型越精确，理想情况的P-R图过点$(1, 1)$，它表示有某个阈值使模型得到了完全正确的分类结果。

在实践中我们认为，如果模型A的P-R图被模型B完全覆盖，则A在任何情况下都劣于B；P-R图与双坐标轴围出的面积越大，模型越优。

但一般的P-R图长相都很不规则，计算其面积较为困难，因此我们取图像上R=P的点，比较取这个点时的横纵坐标值(各自相等)，大者优先。这个点被称为平衡点(Break-Even Point, **BEP**)。

#### F1

离开P-R图，我们放弃对模型的正例阈值的控制，使用模型自己生成的正例阈值，对于一系列输入样例，我们会得到一对唯一的P和R。我们取这一对P和R的调和均值称为F1值：

$$F1=\frac{2PR}{P+R}$$

通过比较不同模型的F1，即可简单地判断其优劣。